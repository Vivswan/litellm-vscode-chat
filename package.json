{
	"name": "litellm-vscode-chat",
	"publisher": "vivswan",
	"displayName": "LiteLLM Provider for GitHub Copilot Chat",
	"description": "An extension that integrates LiteLLM into GitHub Copilot Chat",
	"icon": "assets/logo.png",
	"repository": {
		"type": "git",
		"url": "https://github.com/Vivswan/litellm-vscode-chat"
	},
	"version": "0.1.7",
	"engines": {
		"vscode": "^1.108.0"
	},
	"categories": [
		"AI",
		"Chat"
	],
	"galleryBanner": {
		"color": "#100f11",
		"theme": "dark"
	},
	"badges": [
		{
			"url": "https://img.shields.io/github/stars/Vivswan/litellm-vscode-chat?style=social",
			"description": "Star litellm-vscode-chat on Github",
			"href": "https://github.com/Vivswan/litellm-vscode-chat"
		}
	],
	"homepage": "https://github.com/Vivswan/litellm-vscode-chat",
	"bugs": {
		"url": "https://github.com/Vivswan/litellm-vscode-chat/issues"
	},
	"license": "MIT",
	"contributes": {
		"languageModelChatProviders": [
			{
				"vendor": "litellm",
				"displayName": "LiteLLM",
				"managementCommand": "litellm.manage"
			}
		],
		"commands": [
			{
				"command": "litellm.manage",
				"title": "Manage LiteLLM Provider"
			},
			{
				"command": "litellm.testConnection",
				"title": "LiteLLM: Test Connection"
			},
			{
				"command": "litellm.showDiagnostics",
				"title": "LiteLLM: Show Diagnostics"
			}
		],
		"configuration": {
			"title": "LiteLLM VS Code Chat",
			"properties": {
				"litellm-vscode-chat.defaultMaxOutputTokens": {
					"type": "number",
					"default": 16000,
					"minimum": 1,
					"description": "Default maximum output tokens when not provided by model info"
				},
				"litellm-vscode-chat.defaultContextLength": {
					"type": "number",
					"default": 128000,
					"minimum": 1,
					"description": "Default context length when not provided by model info"
				},
				"litellm-vscode-chat.defaultMaxInputTokens": {
					"type": [
						"number",
						"null"
					],
					"default": null,
					"minimum": 1,
					"description": "Default maximum input tokens (if null, calculated as contextLength - maxOutputTokens)"
				},
				"litellm-vscode-chat.promptCaching.enabled": {
					"type": "boolean",
					"default": true,
					"description": "Enable prompt caching for supported models (currently Anthropic Claude). Caches the system prompt to reduce costs and improve response times. Only affects models that advertise prompt caching support."
				},
				"litellm-vscode-chat.modelParameters": {
					"type": "object",
					"default": {},
					"description": "Model-specific request parameters to customize API behavior. Supports max_tokens, temperature, top_p, frequency_penalty, presence_penalty, stop, etc. Uses longest prefix matching (e.g., 'gpt-4' matches 'gpt-4-turbo:openai').",
					"additionalProperties": {
						"type": "object"
					}
				}
			}
		}
	},
	"main": "./out/extension.js",
	"scripts": {
		"prepare": "husky",
		"vscode:prepublish": "npm run compile",
		"download-api": "dts dev",
		"postdownload-api": "dts main && node -e \"const fs = require('fs'); if (fs.existsSync('vscode.d.ts')) { fs.renameSync('vscode.d.ts', 'src/vscode.d.ts'); console.log('Moved vscode.d.ts to src/'); }\"",
		"postinstall": "npm run download-api",
		"compile": "tsc -p ./",
		"lint": "eslint",
		"format": "prettier --write .",
		"watch": "tsc -watch -p ./",
		"mock-server": "node scripts/mock-litellm-server.js",
		"test": "npm run compile && vscode-test",
		"bump-version": "node scripts/bump-version.js"
	},
	"devDependencies": {
		"@eslint/js": "^9.13.0",
		"@stylistic/eslint-plugin": "^5.7.1",
		"@types/mocha": "^10.0.10",
		"@types/node": "^25.1.0",
		"@types/vscode": "^1.108.1",
		"@vscode/dts": "^0.4.1",
		"@vscode/test-cli": "^0.0.12",
		"@vscode/test-electron": "^2.5.2",
		"eslint": "^9.39.2",
		"husky": "^9.1.7",
		"lint-staged": "^16.2.7",
		"prettier": "^3.8.0",
		"typescript": "^5.9.3",
		"typescript-eslint": "^8.53.0"
	},
	"packageManager": "bun@1.3.6",
	"lint-staged": {
		"*.{js,ts,json,md,yml,yaml}": "prettier --write"
	}
}
